# -*- coding: utf-8 -*-
"""wikipedia_retriever.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11LL_OcPw5mqZ0oc-XCXsEGhYEzAljE-e
"""

# wikipedia_retriever.py

import re
import wikipediaapi
from typing import List, Dict, Optional


class WikipediaRetriever:


    def __init__(
        self,
        language: str = "en",
        user_agent: str = "TKG-Demo/1.0 (contact: example@example.com)",
        min_sentence_len: int = 25,
        max_sentence_len: int = 400,
    ):

        # Wikipedia API client
        self.wiki = wikipediaapi.Wikipedia(
            language=language,
            user_agent=user_agent,
        )

        # Simple in-memory cache: entity -> page_text
        self._page_cache: Dict[str, str] = {}

        self.min_sentence_len = min_sentence_len
        self.max_sentence_len = max_sentence_len

    def _fetch_page_text(self, title: str) -> str:
        """
        Fetches the full page text for a given title.
        Uses cache when possible.
        """
        if title in self._page_cache:
            return self._page_cache[title]

        page = self.wiki.page(title)
        if not page.exists():
            self._page_cache[title] = ""
            return ""

        text = page.text or ""
        self._page_cache[title] = text
        return text

    @staticmethod
    def _split_sentences(text: str) -> List[str]:
        """
        Very simple sentence splitter.
        Good enough for demo-scale experiments.
        """
        # Split on punctuation followed by whitespace
        sentences = re.split(r"(?<=[\.\?\!])\s+", text)
        return [s.strip() for s in sentences if s.strip()]

    def _clean_sentence(self, s: str) -> Optional[str]:
        """
        Apply basic cleaning and length constraints to a sentence.
        Returns cleaned sentence or None if it should be dropped.
        """
        if len(s) < self.min_sentence_len:
            return None

        if len(s) > self.max_sentence_len:
            s = s[: self.max_sentence_len] + "..."

        # Remove weird whitespace
        s = re.sub(r"\s+", " ", s).strip()
        return s


    @staticmethod
    def _sentence_matches_year(
        sentence: str,
        year: Optional[int],
        year_window: int,
    ) -> bool:
        """
        Decide whether a sentence matches the temporal constraint.
        If year is None, returns True always.
        """
        if year is None:
            return True

        years_in_sentence = re.findall(r"\b\d{4}\b", sentence)
        if not years_in_sentence:
            return False

        for y_str in years_in_sentence:
            try:
                y_int = int(y_str)
            except ValueError:
                continue
            if abs(y_int - year) <= year_window:
                return True
        return False


    def get_passages(
        self,
        entities: List[str],
        year: Optional[str],
        max_passages_per_entity: int = 3,
        year_window: int = 1,
        fallback_if_no_year_match: bool = True,
    ) -> List[str]:

        if year is not None:
            try:
                target_year = int(year)
            except ValueError:
                target_year = None
        else:
            target_year = None

        all_passages: List[str] = []

        for ent in entities:
            raw_text = self._fetch_page_text(ent)
            if not raw_text:
                continue

            sentences = self._split_sentences(raw_text)

            # 1) Collect sentences that match year constraint
            selected: List[str] = []
            for s in sentences:
                if not s:
                    continue

                if not self._sentence_matches_year(
                    sentence=s,
                    year=target_year,
                    year_window=year_window,
                ):
                    continue

                cleaned = self._clean_sentence(s)
                if cleaned is None:
                    continue

                selected.append(cleaned)
                if len(selected) >= max_passages_per_entity:
                    break

            # 2) If nothing matched year and fallback is allowed:
            if not selected and fallback_if_no_year_match:
                for s in sentences:
                    cleaned = self._clean_sentence(s)
                    if cleaned is None:
                        continue
                    selected.append(cleaned)
                    if len(selected) >= max_passages_per_entity:
                        break

            all_passages.extend(selected)

        return all_passages